{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"create_1channel_dataset.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"QYQ_MmYbnn5P"},"source":[" # import libraries for modeling\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","import random\n","\n","import os\n","import cv2\n","import glob\n","from skimage.color import rgb2gray"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AQFgf2Zpnn5R"},"source":["## Create Train(40) and Valid(10) Dataset"]},{"cell_type":"code","metadata":{"id":"vNGFa-Wxnn5S"},"source":["for n in range(1, 2):\n","    \n","    random.seed(n)\n","    l = [i for i in range(1, 51)]\n","    random.shuffle(l)\n","    \n","    x_train = np.zeros((5000, 64, 64, 3))\n","    y_train = np.zeros(5000)\n","    # 40개 case를 trainset 으로 저장.\n","    \n","    c = 0\n","    \n","    for j in l[:40]:\n","        if j < 10:\n","            j = '0' + str(j) + '/'\n","        else:\n","            j = str(j) + '/'\n","\n","        path = '/content/drive/Shareddrives/high_classification/train/' + j      \n","\n","        for dirnames, _, filenames in os.walk(path):\n","            filenames = sorted(filenames)\n","\n","            for filename in filenames:    \n","                if filename.endswith('.jpg'):            \n","                    img = cv2.imread(path + filename)\n","\n","                    file_name, file_ext = os.path.splitext(filename)\n","\n","                    with open(path + file_name + '.hytag', 'r') as f:      \n","                        while True:\n","                            line = f.readline()\n","\n","                            if line:\n","                                hytag_list = line.strip().split(',')\n","                                x=int(hytag_list[4]); y=int(hytag_list[5]); w=int(hytag_list[6]); h=int(hytag_list[7])\n","\n","                                if hytag_list[0] == 'LBUID_636802211114365653_0529': # Edema\n","                                    y_train[c] = 1\n","                                elif hytag_list[0] == 'LBUID_636802210898995628_5475': # Normal \n","                                    y_train[c] = 0\n","                                \n","\n","                                x_train[c] = cv2.resize(img[y:y+h, x:x+w], (64, 64))\n","                                c += 1\n","\n","                            else:\n","                                break\n","                                \n","    x_train = x_train[:c, :, :, 0]\n","    y_train = y_train[:c]\n","#     print(x_train.shape)\n","#     print(y_train.shape)\n","    np.save('/content/drive/Shareddrives/high_classification/data/1c/x_train.npy' % (n), x_train)\n","    np.save('/content/drive/Shareddrives/high_classification/data/1c/y_train.npy' % (n), y_train)\n","    \n","    x_valid = np.zeros((5000, 64, 64, 3))\n","    y_valid = np.zeros(5000)\n","    # 40개 case를 trainset 으로 저장.\n","    \n","    c = 0\n","    \n","    for j in l[40:]:\n","        if j < 10:\n","            j = '0' + str(j) + '/'\n","        else:\n","            j = str(j) + '/'\n","\n","\n","        path = '/content/drive/Shareddrives/high_classification/train/' + j      \n","\n","        for dirnames, _, filenames in os.walk(path):\n","            filenames = sorted(filenames)\n","\n","            for filename in filenames:    \n","                if filename.endswith('.jpg'):            \n","                    img = cv2.imread(path + filename)\n","\n","                    file_name, file_ext = os.path.splitext(filename)\n","\n","                    with open(path + file_name + '.hytag', 'r') as f:      \n","                        while True:\n","                            line = f.readline()\n","\n","                            if line:\n","                                hytag_list = line.strip().split(',')\n","                                x=int(hytag_list[4]); y=int(hytag_list[5]); w=int(hytag_list[6]); h=int(hytag_list[7])\n","\n","                                if hytag_list[0] == 'LBUID_636802211114365653_0529': # Edema\n","                                    y_valid[c] = 1\n","                                elif hytag_list[0] == 'LBUID_636802210898995628_5475': # Normal \n","                                    y_valid[c] = 0\n","                                \n","\n","                                x_valid[c] = cv2.resize(img[y:y+h, x:x+w], (64, 64))\n","                                c += 1\n","\n","                            else:\n","                                break\n","                                \n","    x_valid = x_valid[:c, :, :, 0]\n","    y_valid = y_valid[:c]\n","#     print(x_valid.shape)\n","#     print(y_valid.shape)\n","    np.save('/content/drive/Shareddrives/high_classification/data/1c/x_valid.npy' % (n), x_valid)\n","    np.save('/content/drive/Shareddrives/high_classification/data/1c/y_valid.npy' % (n), y_valid)"],"execution_count":null,"outputs":[]}]}