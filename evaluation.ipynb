{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"name":"evaluation.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"e754c967-e559-437f-b1b7-30e0a8ac9d70","outputId":"f0ae89c1-7488-48fc-da69-2d2ecb563248"},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus: \n","    try: # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus: \n","            tf.config.experimental.set_memory_growth(gpu, True)\n","            \n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU') \n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n","    \n","    except RuntimeError as e: # Memory growth must be set before GPUs have been initialized \n","        print(e)"],"id":"e754c967-e559-437f-b1b7-30e0a8ac9d70","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"]}]},{"cell_type":"code","metadata":{"id":"ad9f11c7-85d3-4977-aba2-8834ce703948"},"source":["def performance_check(channel=1):\n","    \n","    aucs = []\n","    accs = []\n","    recalls = []\n","    specs = []\n","    f1scores = []\n","\n","    x_valid = np.load('../data/%dc/x_valid.npy' % (channel))\n","    y_valid = np.load('../data/%dc/y_valid.npy' % (channel))\n","\n","    if channel==1:\n","        x_valid = x_valid.reshape(x_valid.shape[0], 64, 64, 1)\n","\n","    y_valid = y_valid.astype(np.uint8)\n","    x_val_nor = (x_valid / 255.)\n","\n","    model = tf.keras.models.load_model('mc/%dc/ori-loss-model.h5' % (channel))\n","    print(x_val_nor.shape)\n","\n","    pred = model.predict(x_val_nor)\n","    \n","    auc_score = tf.keras.metrics.AUC()\n","    auc_score.update_state(y_valid, pred)\n","    aucs.append(auc_score.result().numpy())\n","\n","    for index, i in enumerate(pred):\n","        if i >= 0.5:\n","            pred[index] = 1\n","        else:\n","            pred[index] = 0\n","\n","    acc = tf.keras.metrics.Accuracy()\n","    acc.update_state(y_valid, pred)\n","    accs.append(acc.result().numpy())\n","\n","    recall = tf.keras.metrics.Recall()\n","    recall.update_state(y_valid, pred)\n","    recalls.append(recall.result().numpy())\n","\n","    spec = tf.keras.metrics.SpecificityAtSensitivity(recall.result().numpy())\n","    spec.update_state(y_valid, pred)\n","    specs.append(spec.result().numpy())\n","\n","    precision = tf.keras.metrics.Precision()\n","    precision.update_state(y_valid, pred)\n","\n","    f1score = 2 * recall.result().numpy() * precision.result().numpy() / (precision.result().numpy() + recall.result().numpy())\n","    f1scores.append(f1score)\n","    \n","    return accs, aucs, recalls, specs, f1scores"],"id":"ad9f11c7-85d3-4977-aba2-8834ce703948","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1113aa0-3b0f-4ec6-81ec-fb0a36640a2e","outputId":"3169b6a3-565c-4bf0-d773-8fefb098b3f8"},"source":["accs, aucs, recalls, specs, f1scores = performance_check(channel=1)\n","accs_2c, aucs_2c, recalls_2c, specs_2c, f1scores_2c = performance_check(channel=2)"],"id":"f1113aa0-3b0f-4ec6-81ec-fb0a36640a2e","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(592, 64, 64, 1)\n","(564, 64, 64, 2)\n"]}]},{"cell_type":"code","metadata":{"id":"25f7aeb5-4872-4f64-adbb-5ed61de4058a","outputId":"35c7bb00-30bc-4a73-91eb-f307302efcde"},"source":["print(accs)"],"id":"25f7aeb5-4872-4f64-adbb-5ed61de4058a","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[0.8496622]\n"]}]},{"cell_type":"code","metadata":{"id":"987650ba-c289-4ba5-b900-841c9ee20946","outputId":"fe4dede1-7f2f-4c36-db85-3a92d0bf41d7"},"source":["print(accs_2c)"],"id":"987650ba-c289-4ba5-b900-841c9ee20946","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[0.8900709]\n"]}]},{"cell_type":"markdown","metadata":{"id":"931ba694-6bd6-43ac-b6c9-683cd677e6f0"},"source":["## model별로 성능을 비교한 그래프 그려보기\n","## matplotlib, seaborn 등 라이브러리 이용"],"id":"931ba694-6bd6-43ac-b6c9-683cd677e6f0"},{"cell_type":"code","metadata":{"id":"70126a9b-9e08-4a15-af83-1a8aa05ec8af"},"source":[""],"id":"70126a9b-9e08-4a15-af83-1a8aa05ec8af","execution_count":null,"outputs":[]}]}