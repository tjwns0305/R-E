{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51867eb-0869-4675-9250-5908f3fae6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D, InputLayer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import Sequential\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    try: # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus: \n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU') \n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n",
    "    \n",
    "    except RuntimeError as e: # Memory growth must be set before GPUs have been initialized \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac77fe00-9389-44cf-ac93-a3ffbee38bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras reproducible \n",
    "import random\n",
    "\n",
    "class config:\n",
    "    seed = 13\n",
    "    \n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything(config.seed)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1, \n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "sess = tf.compat.v1.Session(\n",
    "    graph=tf.compat.v1.get_default_graph(), \n",
    "    config=session_conf\n",
    ")\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150e305-e275-4af3-a657-0c8b5f0f73cc",
   "metadata": {},
   "source": [
    "## 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9ee68a-3230-4b6f-a9be-95c8038008e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(input_shape=(64, 64, 1)):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())  # 3d array from CNN layer to 1d array \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.SGD(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61308765-12d6-47c8-8487-6116c81fe1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,158,017\n",
      "Trainable params: 1,158,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866ac41-4b5b-4fc1-8f21-da2b67272543",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e773dd6-8ccd-4547-b7f9-9543c0dd356b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,158,017\n",
      "Trainable params: 1,158,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "145/145 [==============================] - 2s 8ms/step - loss: 0.6174 - accuracy: 0.7164 - val_loss: 0.6203 - val_accuracy: 0.6909\n",
      "Epoch 2/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5727 - accuracy: 0.7346 - val_loss: 0.6101 - val_accuracy: 0.6909\n",
      "Epoch 3/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5592 - accuracy: 0.7307 - val_loss: 0.5880 - val_accuracy: 0.6909\n",
      "Epoch 4/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5383 - accuracy: 0.7321 - val_loss: 0.5433 - val_accuracy: 0.7128\n",
      "Epoch 5/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.7462 - val_loss: 0.5315 - val_accuracy: 0.7061\n",
      "Epoch 6/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4825 - accuracy: 0.7604 - val_loss: 0.5158 - val_accuracy: 0.7264\n",
      "Epoch 7/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4697 - accuracy: 0.7801 - val_loss: 0.5086 - val_accuracy: 0.7297\n",
      "Epoch 8/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4550 - accuracy: 0.7942 - val_loss: 0.4810 - val_accuracy: 0.7838\n",
      "Epoch 9/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4310 - accuracy: 0.8049 - val_loss: 0.5225 - val_accuracy: 0.7314\n",
      "Epoch 10/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4260 - accuracy: 0.7981 - val_loss: 0.5019 - val_accuracy: 0.7517\n",
      "Epoch 11/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4568 - accuracy: 0.7958 - val_loss: 0.4834 - val_accuracy: 0.7635\n",
      "Epoch 12/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4284 - accuracy: 0.8096 - val_loss: 0.4631 - val_accuracy: 0.7990\n",
      "Epoch 13/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4549 - accuracy: 0.7967 - val_loss: 0.4722 - val_accuracy: 0.7804\n",
      "Epoch 14/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4390 - accuracy: 0.8071 - val_loss: 0.5070 - val_accuracy: 0.7466\n",
      "Epoch 15/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4200 - accuracy: 0.8208 - val_loss: 0.5102 - val_accuracy: 0.7517\n",
      "Epoch 16/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4309 - accuracy: 0.8140 - val_loss: 0.4667 - val_accuracy: 0.7905\n",
      "Epoch 17/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4304 - accuracy: 0.8103 - val_loss: 0.5290 - val_accuracy: 0.7416\n",
      "Epoch 18/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4232 - accuracy: 0.8093 - val_loss: 0.4902 - val_accuracy: 0.7753\n",
      "Epoch 19/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4313 - accuracy: 0.8143 - val_loss: 0.4971 - val_accuracy: 0.7483\n",
      "Epoch 20/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4315 - accuracy: 0.8089 - val_loss: 0.4667 - val_accuracy: 0.7990\n",
      "Epoch 21/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4146 - accuracy: 0.8189 - val_loss: 0.4746 - val_accuracy: 0.7720\n",
      "Epoch 22/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4244 - accuracy: 0.8093 - val_loss: 0.4567 - val_accuracy: 0.8091\n",
      "Epoch 23/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4062 - accuracy: 0.8122 - val_loss: 0.4884 - val_accuracy: 0.7618\n",
      "Epoch 24/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4120 - accuracy: 0.8254 - val_loss: 0.4861 - val_accuracy: 0.7601\n",
      "Epoch 25/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4021 - accuracy: 0.8316 - val_loss: 0.4518 - val_accuracy: 0.8176\n",
      "Epoch 26/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.4048 - accuracy: 0.8305 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 27/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3845 - accuracy: 0.8325 - val_loss: 0.4799 - val_accuracy: 0.7635\n",
      "Epoch 28/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3888 - accuracy: 0.8348 - val_loss: 0.4922 - val_accuracy: 0.7618\n",
      "Epoch 29/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3968 - accuracy: 0.8297 - val_loss: 0.4356 - val_accuracy: 0.8378\n",
      "Epoch 30/200\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.4058 - accuracy: 0.8354 - val_loss: 0.4639 - val_accuracy: 0.7956\n",
      "Epoch 31/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3988 - accuracy: 0.8325 - val_loss: 0.4143 - val_accuracy: 0.8530\n",
      "Epoch 32/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3922 - accuracy: 0.8324 - val_loss: 0.4413 - val_accuracy: 0.8294\n",
      "Epoch 33/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3813 - accuracy: 0.8326 - val_loss: 0.4319 - val_accuracy: 0.8345\n",
      "Epoch 34/200\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.3806 - accuracy: 0.8455 - val_loss: 0.4308 - val_accuracy: 0.8345\n",
      "Epoch 35/200\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.3900 - accuracy: 0.8429 - val_loss: 0.4786 - val_accuracy: 0.7838\n",
      "Epoch 36/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3796 - accuracy: 0.8338 - val_loss: 0.4673 - val_accuracy: 0.7990\n",
      "Epoch 37/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3806 - accuracy: 0.8366 - val_loss: 0.4377 - val_accuracy: 0.8193\n",
      "Epoch 38/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3848 - accuracy: 0.8397 - val_loss: 0.4484 - val_accuracy: 0.8193\n",
      "Epoch 39/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3522 - accuracy: 0.8518 - val_loss: 0.4491 - val_accuracy: 0.8125\n",
      "Epoch 40/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3596 - accuracy: 0.8516 - val_loss: 0.4586 - val_accuracy: 0.8074\n",
      "Epoch 41/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3527 - accuracy: 0.8550 - val_loss: 0.4010 - val_accuracy: 0.8547\n",
      "Epoch 42/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3558 - accuracy: 0.8583 - val_loss: 0.4406 - val_accuracy: 0.8142\n",
      "Epoch 43/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3459 - accuracy: 0.8523 - val_loss: 0.4574 - val_accuracy: 0.8108\n",
      "Epoch 44/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3518 - accuracy: 0.8650 - val_loss: 0.4433 - val_accuracy: 0.8193\n",
      "Epoch 45/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3398 - accuracy: 0.8613 - val_loss: 0.4121 - val_accuracy: 0.8463\n",
      "Epoch 46/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3579 - accuracy: 0.8476 - val_loss: 0.4391 - val_accuracy: 0.8226\n",
      "Epoch 47/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3467 - accuracy: 0.8704 - val_loss: 0.4138 - val_accuracy: 0.8598\n",
      "Epoch 48/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3362 - accuracy: 0.8620 - val_loss: 0.4089 - val_accuracy: 0.8429\n",
      "Epoch 49/200\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.3291 - accuracy: 0.8646 - val_loss: 0.4051 - val_accuracy: 0.8514\n",
      "Epoch 50/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3494 - accuracy: 0.8514 - val_loss: 0.3930 - val_accuracy: 0.8514\n",
      "Epoch 51/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3256 - accuracy: 0.8647 - val_loss: 0.4404 - val_accuracy: 0.8226\n",
      "Epoch 52/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3042 - accuracy: 0.8859 - val_loss: 0.4124 - val_accuracy: 0.8480\n",
      "Epoch 53/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3263 - accuracy: 0.8674 - val_loss: 0.4269 - val_accuracy: 0.8260\n",
      "Epoch 54/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2841 - accuracy: 0.8858 - val_loss: 0.4116 - val_accuracy: 0.8480\n",
      "Epoch 55/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3321 - accuracy: 0.8656 - val_loss: 0.3998 - val_accuracy: 0.8514\n",
      "Epoch 56/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2818 - accuracy: 0.8885 - val_loss: 0.4016 - val_accuracy: 0.8581\n",
      "Epoch 57/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2916 - accuracy: 0.8831 - val_loss: 0.3989 - val_accuracy: 0.8564\n",
      "Epoch 58/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.3035 - accuracy: 0.8750 - val_loss: 0.4846 - val_accuracy: 0.8142\n",
      "Epoch 59/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2883 - accuracy: 0.8793 - val_loss: 0.4065 - val_accuracy: 0.8412\n",
      "Epoch 60/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2884 - accuracy: 0.8791 - val_loss: 0.4205 - val_accuracy: 0.8412\n",
      "Epoch 61/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2749 - accuracy: 0.8944 - val_loss: 0.4106 - val_accuracy: 0.8361\n",
      "Epoch 62/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2779 - accuracy: 0.8909 - val_loss: 0.4254 - val_accuracy: 0.8345\n",
      "Epoch 63/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2938 - accuracy: 0.8880 - val_loss: 0.4077 - val_accuracy: 0.8328\n",
      "Epoch 64/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2980 - accuracy: 0.8693 - val_loss: 0.4608 - val_accuracy: 0.8193\n",
      "Epoch 65/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2907 - accuracy: 0.8775 - val_loss: 0.4563 - val_accuracy: 0.8176\n",
      "Epoch 66/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2572 - accuracy: 0.8968 - val_loss: 0.4052 - val_accuracy: 0.8547\n",
      "Epoch 67/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2381 - accuracy: 0.8993 - val_loss: 0.4562 - val_accuracy: 0.8277\n",
      "Epoch 68/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2659 - accuracy: 0.8894 - val_loss: 0.5087 - val_accuracy: 0.8074\n",
      "Epoch 69/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2560 - accuracy: 0.8943 - val_loss: 0.4412 - val_accuracy: 0.8243\n",
      "Epoch 70/200\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.2356 - accuracy: 0.9085 - val_loss: 0.4084 - val_accuracy: 0.8480\n",
      "Epoch 71/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2089 - accuracy: 0.9165 - val_loss: 0.4431 - val_accuracy: 0.8294\n",
      "Epoch 72/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2156 - accuracy: 0.9110 - val_loss: 0.4473 - val_accuracy: 0.8243\n",
      "Epoch 73/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2181 - accuracy: 0.9054 - val_loss: 0.4757 - val_accuracy: 0.8193\n",
      "Epoch 74/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2059 - accuracy: 0.9196 - val_loss: 0.5300 - val_accuracy: 0.7905\n",
      "Epoch 75/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2132 - accuracy: 0.9134 - val_loss: 0.4469 - val_accuracy: 0.8294\n",
      "Epoch 76/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2080 - accuracy: 0.9162 - val_loss: 0.4217 - val_accuracy: 0.8361\n",
      "Epoch 77/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.9085 - val_loss: 0.4711 - val_accuracy: 0.8193\n",
      "Epoch 78/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1787 - accuracy: 0.9239 - val_loss: 0.4664 - val_accuracy: 0.8007\n",
      "Epoch 79/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1778 - accuracy: 0.9313 - val_loss: 0.5235 - val_accuracy: 0.8176\n",
      "Epoch 80/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1852 - accuracy: 0.9244 - val_loss: 0.4756 - val_accuracy: 0.8243\n",
      "Epoch 81/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1636 - accuracy: 0.9357 - val_loss: 0.3845 - val_accuracy: 0.8497\n",
      "Epoch 82/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1820 - accuracy: 0.9273 - val_loss: 0.5576 - val_accuracy: 0.8226\n",
      "Epoch 83/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1688 - accuracy: 0.9347 - val_loss: 0.4499 - val_accuracy: 0.8446\n",
      "Epoch 84/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1816 - accuracy: 0.9303 - val_loss: 0.4430 - val_accuracy: 0.8311\n",
      "Epoch 85/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1705 - accuracy: 0.9386 - val_loss: 0.5382 - val_accuracy: 0.8193\n",
      "Epoch 86/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1545 - accuracy: 0.9465 - val_loss: 0.4389 - val_accuracy: 0.8311\n",
      "Epoch 87/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1929 - accuracy: 0.9207 - val_loss: 0.3987 - val_accuracy: 0.8378\n",
      "Epoch 88/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1454 - accuracy: 0.9464 - val_loss: 0.6365 - val_accuracy: 0.7956\n",
      "Epoch 89/200\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1257 - accuracy: 0.9503 - val_loss: 0.5285 - val_accuracy: 0.8176\n",
      "Epoch 90/200\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.1316 - accuracy: 0.9502 - val_loss: 0.4450 - val_accuracy: 0.8412\n",
      "Epoch 91/200\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.1596 - accuracy: 0.9360 - val_loss: 0.4514 - val_accuracy: 0.8446\n",
      "Epoch 92/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1328 - accuracy: 0.9465 - val_loss: 0.4831 - val_accuracy: 0.8226\n",
      "Epoch 93/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1192 - accuracy: 0.9519 - val_loss: 0.4846 - val_accuracy: 0.8260\n",
      "Epoch 94/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.9439 - val_loss: 0.5028 - val_accuracy: 0.8328\n",
      "Epoch 95/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1129 - accuracy: 0.9570 - val_loss: 0.6466 - val_accuracy: 0.7872\n",
      "Epoch 96/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1072 - accuracy: 0.9644 - val_loss: 0.6036 - val_accuracy: 0.7889\n",
      "Epoch 97/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0961 - accuracy: 0.9636 - val_loss: 0.5018 - val_accuracy: 0.8311\n",
      "Epoch 98/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0925 - accuracy: 0.9676 - val_loss: 0.5188 - val_accuracy: 0.7990\n",
      "Epoch 99/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0932 - accuracy: 0.9702 - val_loss: 0.5430 - val_accuracy: 0.7939\n",
      "Epoch 100/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0885 - accuracy: 0.9670 - val_loss: 0.6532 - val_accuracy: 0.8041\n",
      "Epoch 101/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0700 - accuracy: 0.9778 - val_loss: 0.4991 - val_accuracy: 0.8429\n",
      "Epoch 102/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9763 - val_loss: 0.5243 - val_accuracy: 0.8057\n",
      "Epoch 103/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0942 - accuracy: 0.9683 - val_loss: 0.6030 - val_accuracy: 0.8243\n",
      "Epoch 104/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0883 - accuracy: 0.9676 - val_loss: 0.6317 - val_accuracy: 0.8057\n",
      "Epoch 105/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0680 - accuracy: 0.9724 - val_loss: 0.5536 - val_accuracy: 0.8463\n",
      "Epoch 106/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0703 - accuracy: 0.9769 - val_loss: 0.6464 - val_accuracy: 0.8125\n",
      "Epoch 107/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9670 - val_loss: 0.7645 - val_accuracy: 0.7787\n",
      "Epoch 108/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0593 - accuracy: 0.9766 - val_loss: 0.6411 - val_accuracy: 0.8074\n",
      "Epoch 109/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0646 - accuracy: 0.9755 - val_loss: 0.6198 - val_accuracy: 0.8260\n",
      "Epoch 110/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0584 - accuracy: 0.9784 - val_loss: 0.6027 - val_accuracy: 0.8041\n",
      "Epoch 111/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0583 - accuracy: 0.9807 - val_loss: 0.6371 - val_accuracy: 0.7804\n",
      "Epoch 112/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0557 - accuracy: 0.9799 - val_loss: 0.7118 - val_accuracy: 0.8142\n",
      "Epoch 113/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0603 - accuracy: 0.9764 - val_loss: 0.6999 - val_accuracy: 0.8091\n",
      "Epoch 114/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.6368 - val_accuracy: 0.8057\n",
      "Epoch 115/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0620 - accuracy: 0.9715 - val_loss: 0.7482 - val_accuracy: 0.8125\n",
      "Epoch 116/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0593 - accuracy: 0.9771 - val_loss: 0.6473 - val_accuracy: 0.8074\n",
      "Epoch 117/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.6101 - val_accuracy: 0.8361\n",
      "Epoch 118/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0562 - accuracy: 0.9750 - val_loss: 0.5492 - val_accuracy: 0.8345\n",
      "Epoch 119/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9836 - val_loss: 0.6424 - val_accuracy: 0.8091\n",
      "Epoch 120/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0461 - accuracy: 0.9822 - val_loss: 0.6937 - val_accuracy: 0.8209\n",
      "Epoch 121/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9924 - val_loss: 0.7389 - val_accuracy: 0.8041\n",
      "Epoch 122/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0369 - accuracy: 0.9883 - val_loss: 0.6752 - val_accuracy: 0.8328\n",
      "Epoch 123/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0454 - accuracy: 0.9851 - val_loss: 0.6594 - val_accuracy: 0.8057\n",
      "Epoch 124/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9677 - val_loss: 0.6110 - val_accuracy: 0.7956\n",
      "Epoch 125/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9777 - val_loss: 0.6331 - val_accuracy: 0.8159\n",
      "Epoch 126/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.6726 - val_accuracy: 0.8176\n",
      "Epoch 127/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.6087 - val_accuracy: 0.8057\n",
      "Epoch 128/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.6023 - val_accuracy: 0.8243\n",
      "Epoch 129/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.6766 - val_accuracy: 0.8091\n",
      "Epoch 130/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 0.7045 - val_accuracy: 0.7973\n",
      "Epoch 131/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0288 - accuracy: 0.9885 - val_loss: 0.9262 - val_accuracy: 0.8007\n",
      "Epoch 132/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9862 - val_loss: 0.7326 - val_accuracy: 0.8260\n",
      "Epoch 133/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.7781 - val_accuracy: 0.7855\n",
      "Epoch 134/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0405 - accuracy: 0.9846 - val_loss: 0.7979 - val_accuracy: 0.8209\n",
      "Epoch 135/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9907 - val_loss: 0.8961 - val_accuracy: 0.8091\n",
      "Epoch 136/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.7972 - val_accuracy: 0.8159\n",
      "Epoch 137/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0234 - accuracy: 0.9895 - val_loss: 0.8660 - val_accuracy: 0.8057\n",
      "Epoch 138/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9893 - val_loss: 0.7623 - val_accuracy: 0.8193\n",
      "Epoch 139/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.8071 - val_accuracy: 0.8091\n",
      "Epoch 140/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.9361 - val_accuracy: 0.8108\n",
      "Epoch 141/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.8009 - val_accuracy: 0.8193\n",
      "Epoch 142/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0322 - accuracy: 0.9875 - val_loss: 0.7491 - val_accuracy: 0.8125\n",
      "Epoch 143/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 1.0154 - val_accuracy: 0.8074\n",
      "Epoch 144/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 1.1932 - val_accuracy: 0.7905\n",
      "Epoch 145/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.8886 - val_accuracy: 0.8260\n",
      "Epoch 146/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.8914 - val_accuracy: 0.8176\n",
      "Epoch 147/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 1.0103 - val_accuracy: 0.8091\n",
      "Epoch 148/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1955 - accuracy: 0.9543 - val_loss: 0.5217 - val_accuracy: 0.8463\n",
      "Epoch 149/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.7316 - val_accuracy: 0.8142\n",
      "Epoch 150/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.7389 - val_accuracy: 0.8176\n",
      "Epoch 151/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.6944 - val_accuracy: 0.8209\n",
      "Epoch 152/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.7660 - val_accuracy: 0.7855\n",
      "Epoch 153/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.8909 - val_accuracy: 0.8108\n",
      "Epoch 154/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.7426 - val_accuracy: 0.8159\n",
      "Epoch 155/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.8389 - val_accuracy: 0.7922\n",
      "Epoch 156/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9873 - val_loss: 0.9644 - val_accuracy: 0.8091\n",
      "Epoch 157/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0227 - accuracy: 0.9904 - val_loss: 0.8954 - val_accuracy: 0.8108\n",
      "Epoch 158/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 1.0120 - val_accuracy: 0.8108\n",
      "Epoch 159/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.8808 - val_accuracy: 0.7922\n",
      "Epoch 160/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.9684 - val_accuracy: 0.8226\n",
      "Epoch 161/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0225 - accuracy: 0.9903 - val_loss: 1.0750 - val_accuracy: 0.8125\n",
      "Epoch 162/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0188 - accuracy: 0.9917 - val_loss: 1.0190 - val_accuracy: 0.8193\n",
      "Epoch 163/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.8949 - val_accuracy: 0.8074\n",
      "Epoch 164/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.8143 - val_accuracy: 0.8125\n",
      "Epoch 165/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.9564 - val_accuracy: 0.8125\n",
      "Epoch 166/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.8856 - val_accuracy: 0.7787\n",
      "Epoch 167/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.9366 - val_accuracy: 0.8091\n",
      "Epoch 168/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 1.1086 - val_accuracy: 0.8091\n",
      "Epoch 169/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9925 - val_loss: 0.9486 - val_accuracy: 0.8142\n",
      "Epoch 170/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.8404 - val_accuracy: 0.8260\n",
      "Epoch 171/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0238 - accuracy: 0.9903 - val_loss: 1.0185 - val_accuracy: 0.8142\n",
      "Epoch 172/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.9134 - val_accuracy: 0.8243\n",
      "Epoch 173/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.9377 - val_accuracy: 0.8057\n",
      "Epoch 174/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.9829 - val_accuracy: 0.7990\n",
      "Epoch 175/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.9757 - val_accuracy: 0.8243\n",
      "Epoch 176/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9940 - val_loss: 0.9512 - val_accuracy: 0.8209\n",
      "Epoch 177/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 1.0272 - val_accuracy: 0.8057\n",
      "Epoch 178/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 1.2508 - val_accuracy: 0.8024\n",
      "Epoch 179/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 0.9876 - val_accuracy: 0.7939\n",
      "Epoch 180/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 1.2018 - val_accuracy: 0.7922\n",
      "Epoch 181/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.0146 - val_accuracy: 0.7956\n",
      "Epoch 182/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 1.0579 - val_accuracy: 0.8142\n",
      "Epoch 183/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.9874 - val_accuracy: 0.7922\n",
      "Epoch 184/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9927 - val_loss: 1.0094 - val_accuracy: 0.8074\n",
      "Epoch 185/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.9148 - val_accuracy: 0.8024\n",
      "Epoch 186/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0084 - accuracy: 0.9965 - val_loss: 1.0150 - val_accuracy: 0.8041\n",
      "Epoch 187/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0096 - accuracy: 0.9962 - val_loss: 1.0738 - val_accuracy: 0.7872\n",
      "Epoch 188/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 1.0288 - val_accuracy: 0.8108\n",
      "Epoch 189/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 1.0111 - val_accuracy: 0.8041\n",
      "Epoch 190/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 1.0292 - val_accuracy: 0.8091\n",
      "Epoch 191/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 1.0500 - val_accuracy: 0.8125\n",
      "Epoch 192/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 1.1241 - val_accuracy: 0.8024\n",
      "Epoch 193/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 1.0352 - val_accuracy: 0.7990\n",
      "Epoch 194/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 1.0394 - val_accuracy: 0.8091\n",
      "Epoch 195/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 1.0842 - val_accuracy: 0.8007\n",
      "Epoch 196/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.9221 - val_accuracy: 0.8176\n",
      "Epoch 197/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 1.0496 - val_accuracy: 0.8209\n",
      "Epoch 198/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 1.0641 - val_accuracy: 0.8125\n",
      "Epoch 199/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.9921 - val_accuracy: 0.8125\n",
      "Epoch 200/200\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 1.0181 - val_accuracy: 0.8277\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "x_train = np.load('../data/1c/x_train.npy')\n",
    "y_train = np.load('../data/1c/y_train.npy')\n",
    "\n",
    "x_valid = np.load('../data/1c/x_valid.npy')\n",
    "y_valid = np.load('../data/1c/y_valid.npy')\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 64, 64, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], 64, 64, 1)\n",
    "\n",
    "input_shape = (64, 64, 1)\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=13) \n",
    "\n",
    "y_train = y_train.astype(np.uint8)\n",
    "y_valid = y_valid.astype(np.uint8)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "valid_generator = valid_datagen.flow(x_valid, y_valid, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = model_2()\n",
    "model.summary()\n",
    "\n",
    "# model checkpoint\n",
    "mc = ModelCheckpoint('mc/1c/ori-loss-model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# train -- fit\n",
    "history = model.fit(\n",
    "train_generator,\n",
    "epochs=epochs,\n",
    "validation_data=valid_generator,\n",
    "callbacks=[mc],\n",
    "workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c6f45-b97d-4c82-bd65-b25691339c30",
   "metadata": {},
   "source": [
    "## DataAugmentation 적용해보기\n",
    "## ImageDataGenerator사용하거나, 직접 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85232553-8587-4e4b-ac1d-9eaa1709630b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
