{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"name":"training-2c.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"e51867eb-0869-4675-9250-5908f3fae6bf","outputId":"e5359b55-d4d9-43b4-c277-ce02da37878f"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D, InputLayer\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import Sequential\n","from keras import regularizers\n","from keras.callbacks import ModelCheckpoint\n","from sklearn.utils import shuffle \n","\n","import multiprocessing\n","\n","import os\n","import cv2\n","import time\n","import gc\n","\n","from PIL import Image\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus: \n","    try: # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus: \n","            tf.config.experimental.set_memory_growth(gpu, True)\n","            \n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU') \n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n","    \n","    except RuntimeError as e: # Memory growth must be set before GPUs have been initialized \n","        print(e)"],"id":"e51867eb-0869-4675-9250-5908f3fae6bf","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"]}]},{"cell_type":"code","metadata":{"tags":[],"id":"ac77fe00-9389-44cf-ac93-a3ffbee38bd2"},"source":["# keras reproducible \n","import random\n","\n","class config:\n","    seed = 13\n","    \n","def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    tf.random.set_seed(seed)\n","    \n","seed_everything(config.seed)\n","\n","session_conf = tf.compat.v1.ConfigProto(\n","    intra_op_parallelism_threads=1, \n","    inter_op_parallelism_threads=1\n",")\n","sess = tf.compat.v1.Session(\n","    graph=tf.compat.v1.get_default_graph(), \n","    config=session_conf\n",")\n","tf.compat.v1.keras.backend.set_session(sess)"],"id":"ac77fe00-9389-44cf-ac93-a3ffbee38bd2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6a9ee68a-3230-4b6f-a9be-95c8038008e5"},"source":["def model_2(input_shape=(64, 64, 1)):\n","\n","    model = Sequential()\n","    \n","    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(128, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","    \n","    model.add(Flatten())  # 3d array from CNN layer to 1d array \n","    model.add(Dense(128))\n","    model.add(Activation('relu'))\n","    \n","    model.add(Dense(128))\n","    model.add(Activation('relu'))\n","    \n","    model.add(Dense(1))\n","    model.add(Activation('sigmoid'))\n","\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=tf.keras.optimizers.SGD(),\n","                  metrics=['accuracy'])\n","    return model"],"id":"6a9ee68a-3230-4b6f-a9be-95c8038008e5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"61308765-12d6-47c8-8487-6116c81fe1ae","outputId":"f6a6cd93-001e-4b30-83b1-5d311893c6ea"},"source":["model = model_2()\n","model.summary()"],"id":"61308765-12d6-47c8-8487-6116c81fe1ae","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 64, 64, 32)        320       \n","_________________________________________________________________\n","activation (Activation)      (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 8192)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               1048704   \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 129       \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 1,158,017\n","Trainable params: 1,158,017\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"scrolled":true,"tags":[],"id":"5e773dd6-8ccd-4547-b7f9-9543c0dd356b","outputId":"2b143f34-4794-4477-b1b0-2f9cc837a668"},"source":["batch_size = 16\n","epochs = 200\n","\n","\n","x_train = np.load('../data/2c/x_train.npy')\n","y_train = np.load('../data/2c/y_train.npy')\n","x_valid = np.load('../data/2c/x_valid.npy')\n","y_valid = np.load('../data/2c/y_valid.npy')\n","\n","# x_train = x_train.reshape(x_train.shape[0], 64, 64, 1)\n","# x_valid = x_valid.reshape(x_valid.shape[0], 64, 64, 1)\n","\n","input_shape = (64, 64, 2)\n","\n","x_train, y_train = shuffle(x_train, y_train, random_state=13) \n","\n","y_train = y_train.astype(np.uint8)\n","y_valid = y_valid.astype(np.uint8)\n","\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n","valid_generator = valid_datagen.flow(x_valid, y_valid, batch_size=batch_size)\n","\n","# for i in range(2, 3):\n","model = model_2(input_shape=input_shape)\n","model.summary()\n","# model checkpoint\n","\n","mc = ModelCheckpoint('mc/2c/ori-loss-model.h5', monitor='val_loss', mode='min', save_best_only=True)\n","\n","# train -- fit\n","history = model.fit(\n","train_generator,\n","epochs=epochs,\n","validation_data=valid_generator,\n","callbacks=[mc],\n","workers=8\n",")"],"id":"5e773dd6-8ccd-4547-b7f9-9543c0dd356b","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["/home/miruware/anaconda3/envs/pcs/lib/python3.8/site-packages/keras_preprocessing/image/numpy_array_iterator.py:129: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2188, 64, 64, 2) (2 channels).\n","  warnings.warn('NumpyArrayIterator is set to use the '\n","/home/miruware/anaconda3/envs/pcs/lib/python3.8/site-packages/keras_preprocessing/image/numpy_array_iterator.py:129: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (564, 64, 64, 2) (2 channels).\n","  warnings.warn('NumpyArrayIterator is set to use the '\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 64, 64, 32)        608       \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 8192)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               1048704   \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 128)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 128)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 1)                 129       \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 1)                 0         \n","=================================================================\n","Total params: 1,158,305\n","Trainable params: 1,158,305\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/200\n","137/137 [==============================] - 2s 9ms/step - loss: 0.6253 - accuracy: 0.6969 - val_loss: 0.6228 - val_accuracy: 0.6933\n","Epoch 2/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.5808 - accuracy: 0.7387 - val_loss: 0.6190 - val_accuracy: 0.6933\n","Epoch 3/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.5657 - accuracy: 0.7434 - val_loss: 0.6047 - val_accuracy: 0.6933\n","Epoch 4/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.5423 - accuracy: 0.7355 - val_loss: 0.5715 - val_accuracy: 0.6933\n","Epoch 5/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.5288 - accuracy: 0.7499 - val_loss: 0.6592 - val_accuracy: 0.6933\n","Epoch 6/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4821 - accuracy: 0.7852 - val_loss: 0.6118 - val_accuracy: 0.6933\n","Epoch 7/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4584 - accuracy: 0.7842 - val_loss: 0.5584 - val_accuracy: 0.6986\n","Epoch 8/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4648 - accuracy: 0.7850 - val_loss: 0.4873 - val_accuracy: 0.7730\n","Epoch 9/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4546 - accuracy: 0.8025 - val_loss: 0.5500 - val_accuracy: 0.6950\n","Epoch 10/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4426 - accuracy: 0.7974 - val_loss: 0.5414 - val_accuracy: 0.7039\n","Epoch 11/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4373 - accuracy: 0.8026 - val_loss: 0.4906 - val_accuracy: 0.7465\n","Epoch 12/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4271 - accuracy: 0.8134 - val_loss: 0.5047 - val_accuracy: 0.7465\n","Epoch 13/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4280 - accuracy: 0.8127 - val_loss: 0.5002 - val_accuracy: 0.7447\n","Epoch 14/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4292 - accuracy: 0.8128 - val_loss: 0.5233 - val_accuracy: 0.7252\n","Epoch 15/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.8121 - val_loss: 0.4891 - val_accuracy: 0.7518\n","Epoch 16/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4023 - accuracy: 0.8273 - val_loss: 0.5100 - val_accuracy: 0.7340\n","Epoch 17/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4217 - accuracy: 0.8191 - val_loss: 0.4347 - val_accuracy: 0.8174\n","Epoch 18/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4247 - accuracy: 0.8195 - val_loss: 0.4370 - val_accuracy: 0.8280\n","Epoch 19/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4131 - accuracy: 0.8267 - val_loss: 0.4287 - val_accuracy: 0.8511\n","Epoch 20/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4137 - accuracy: 0.8114 - val_loss: 0.4498 - val_accuracy: 0.7979\n","Epoch 21/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4083 - accuracy: 0.8295 - val_loss: 0.4200 - val_accuracy: 0.8617\n","Epoch 22/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3943 - accuracy: 0.8443 - val_loss: 0.4635 - val_accuracy: 0.7819\n","Epoch 23/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3979 - accuracy: 0.8295 - val_loss: 0.4788 - val_accuracy: 0.7571\n","Epoch 24/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4048 - accuracy: 0.8261 - val_loss: 0.4840 - val_accuracy: 0.7589\n","Epoch 25/200\n","137/137 [==============================] - 1s 7ms/step - loss: 0.4003 - accuracy: 0.8346 - val_loss: 0.5476 - val_accuracy: 0.7199\n","Epoch 26/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.4014 - accuracy: 0.8342 - val_loss: 0.3991 - val_accuracy: 0.8706\n","Epoch 27/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3850 - accuracy: 0.8330 - val_loss: 0.4911 - val_accuracy: 0.7571\n","Epoch 28/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3892 - accuracy: 0.8333 - val_loss: 0.4762 - val_accuracy: 0.7606\n","Epoch 29/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3690 - accuracy: 0.8524 - val_loss: 0.4860 - val_accuracy: 0.7429\n","Epoch 30/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3560 - accuracy: 0.8534 - val_loss: 0.4261 - val_accuracy: 0.8103\n","Epoch 31/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3601 - accuracy: 0.8503 - val_loss: 0.4335 - val_accuracy: 0.7943\n","Epoch 32/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3696 - accuracy: 0.8430 - val_loss: 0.3984 - val_accuracy: 0.8688\n","Epoch 33/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3550 - accuracy: 0.8427 - val_loss: 0.4327 - val_accuracy: 0.7961\n","Epoch 34/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3583 - accuracy: 0.8464 - val_loss: 0.4147 - val_accuracy: 0.8280\n","Epoch 35/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3646 - accuracy: 0.8538 - val_loss: 0.4322 - val_accuracy: 0.8014\n","Epoch 36/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3341 - accuracy: 0.8627 - val_loss: 0.3961 - val_accuracy: 0.8599\n","Epoch 37/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3682 - accuracy: 0.8398 - val_loss: 0.4577 - val_accuracy: 0.7660\n","Epoch 38/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3554 - accuracy: 0.8441 - val_loss: 0.3826 - val_accuracy: 0.8546\n","Epoch 39/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3476 - accuracy: 0.8447 - val_loss: 0.4714 - val_accuracy: 0.7589\n","Epoch 40/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3108 - accuracy: 0.8730 - val_loss: 0.3988 - val_accuracy: 0.8369\n","Epoch 41/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3442 - accuracy: 0.8600 - val_loss: 0.3984 - val_accuracy: 0.8387\n","Epoch 42/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3531 - accuracy: 0.8486 - val_loss: 0.4552 - val_accuracy: 0.7801\n","Epoch 43/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3185 - accuracy: 0.8678 - val_loss: 0.4478 - val_accuracy: 0.7908\n","Epoch 44/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3149 - accuracy: 0.8757 - val_loss: 0.4002 - val_accuracy: 0.8351\n","Epoch 45/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3155 - accuracy: 0.8751 - val_loss: 0.4620 - val_accuracy: 0.7730\n","Epoch 46/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.8758 - val_loss: 0.4097 - val_accuracy: 0.8209\n","Epoch 47/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2977 - accuracy: 0.8698 - val_loss: 0.3660 - val_accuracy: 0.8723\n","Epoch 48/200\n","137/137 [==============================] - 1s 7ms/step - loss: 0.3351 - accuracy: 0.8497 - val_loss: 0.4325 - val_accuracy: 0.8085\n","Epoch 49/200\n","137/137 [==============================] - 1s 7ms/step - loss: 0.2955 - accuracy: 0.8761 - val_loss: 0.3745 - val_accuracy: 0.8688\n","Epoch 50/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2634 - accuracy: 0.8929 - val_loss: 0.3942 - val_accuracy: 0.8528\n","Epoch 51/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2992 - accuracy: 0.8746 - val_loss: 0.4130 - val_accuracy: 0.8262\n","Epoch 52/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2900 - accuracy: 0.8896 - val_loss: 0.3430 - val_accuracy: 0.8901\n","Epoch 53/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2942 - accuracy: 0.8719 - val_loss: 0.4117 - val_accuracy: 0.8245\n","Epoch 54/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2828 - accuracy: 0.8908 - val_loss: 0.4037 - val_accuracy: 0.8298\n","Epoch 55/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2653 - accuracy: 0.8870 - val_loss: 0.3586 - val_accuracy: 0.8617\n","Epoch 56/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2770 - accuracy: 0.8860 - val_loss: 0.4215 - val_accuracy: 0.8280\n","Epoch 57/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2582 - accuracy: 0.8946 - val_loss: 0.4414 - val_accuracy: 0.8156\n","Epoch 58/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2597 - accuracy: 0.8985 - val_loss: 0.3749 - val_accuracy: 0.8599\n","Epoch 59/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2609 - accuracy: 0.8913 - val_loss: 0.3992 - val_accuracy: 0.8351\n","Epoch 60/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2594 - accuracy: 0.8908 - val_loss: 0.3520 - val_accuracy: 0.8652\n","Epoch 61/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2527 - accuracy: 0.8936 - val_loss: 0.3996 - val_accuracy: 0.8528\n","Epoch 62/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2428 - accuracy: 0.9068 - val_loss: 0.4020 - val_accuracy: 0.8422\n","Epoch 63/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2193 - accuracy: 0.9127 - val_loss: 0.4038 - val_accuracy: 0.8351\n","Epoch 64/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2384 - accuracy: 0.9034 - val_loss: 0.3643 - val_accuracy: 0.8582\n","Epoch 65/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2093 - accuracy: 0.9128 - val_loss: 0.3983 - val_accuracy: 0.8387\n","Epoch 66/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2302 - accuracy: 0.9026 - val_loss: 0.4844 - val_accuracy: 0.8085\n","Epoch 67/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2300 - accuracy: 0.9015 - val_loss: 0.4210 - val_accuracy: 0.8333\n","Epoch 68/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.2018 - accuracy: 0.9157 - val_loss: 0.4444 - val_accuracy: 0.8280\n","Epoch 69/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1968 - accuracy: 0.9199 - val_loss: 0.3615 - val_accuracy: 0.8670\n","Epoch 70/200\n","137/137 [==============================] - 1s 7ms/step - loss: 0.1990 - accuracy: 0.9265 - val_loss: 0.3791 - val_accuracy: 0.8564\n","Epoch 71/200\n","137/137 [==============================] - 1s 7ms/step - loss: 0.1970 - accuracy: 0.9083 - val_loss: 0.4401 - val_accuracy: 0.8440\n","Epoch 72/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1816 - accuracy: 0.9271 - val_loss: 0.3474 - val_accuracy: 0.8670\n","Epoch 73/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1644 - accuracy: 0.9424 - val_loss: 0.3857 - val_accuracy: 0.8422\n","Epoch 74/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1717 - accuracy: 0.9282 - val_loss: 0.4446 - val_accuracy: 0.8333\n","Epoch 75/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1707 - accuracy: 0.9334 - val_loss: 0.3691 - val_accuracy: 0.8493\n","Epoch 76/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1784 - accuracy: 0.9233 - val_loss: 0.4233 - val_accuracy: 0.8493\n","Epoch 77/200\n","137/137 [==============================] - 1s 7ms/step - loss: 0.1565 - accuracy: 0.9405 - val_loss: 0.3952 - val_accuracy: 0.8422\n","Epoch 78/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1374 - accuracy: 0.9447 - val_loss: 0.4736 - val_accuracy: 0.8404\n","Epoch 79/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1501 - accuracy: 0.9379 - val_loss: 0.3962 - val_accuracy: 0.8316\n","Epoch 80/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1277 - accuracy: 0.9471 - val_loss: 0.4845 - val_accuracy: 0.8387\n","Epoch 81/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1166 - accuracy: 0.9566 - val_loss: 0.3869 - val_accuracy: 0.8298\n","Epoch 82/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1267 - accuracy: 0.9531 - val_loss: 0.3812 - val_accuracy: 0.8582\n","Epoch 83/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1304 - accuracy: 0.9500 - val_loss: 0.5471 - val_accuracy: 0.8014\n","Epoch 84/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1007 - accuracy: 0.9606 - val_loss: 0.3960 - val_accuracy: 0.8298\n","Epoch 85/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1052 - accuracy: 0.9635 - val_loss: 0.4994 - val_accuracy: 0.8245\n","Epoch 86/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.1031 - accuracy: 0.9593 - val_loss: 0.4470 - val_accuracy: 0.8528\n","Epoch 87/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0954 - accuracy: 0.9655 - val_loss: 0.4307 - val_accuracy: 0.8369\n","Epoch 88/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0867 - accuracy: 0.9660 - val_loss: 0.4921 - val_accuracy: 0.8333\n","Epoch 89/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0926 - accuracy: 0.9598 - val_loss: 0.5137 - val_accuracy: 0.8209\n","Epoch 90/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0886 - accuracy: 0.9676 - val_loss: 0.4452 - val_accuracy: 0.8316\n","Epoch 91/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0781 - accuracy: 0.9746 - val_loss: 0.5193 - val_accuracy: 0.8298\n","Epoch 92/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0863 - accuracy: 0.9646 - val_loss: 0.5425 - val_accuracy: 0.8014\n","Epoch 93/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0736 - accuracy: 0.9734 - val_loss: 0.5201 - val_accuracy: 0.8422\n","Epoch 94/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0797 - accuracy: 0.9698 - val_loss: 0.5813 - val_accuracy: 0.8369\n","Epoch 95/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0756 - accuracy: 0.9701 - val_loss: 0.5200 - val_accuracy: 0.8227\n","Epoch 96/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0712 - accuracy: 0.9811 - val_loss: 0.5342 - val_accuracy: 0.8227\n","Epoch 97/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0627 - accuracy: 0.9767 - val_loss: 0.6054 - val_accuracy: 0.8351\n","Epoch 98/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 0.5506 - val_accuracy: 0.8227\n","Epoch 99/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0508 - accuracy: 0.9812 - val_loss: 0.6143 - val_accuracy: 0.8351\n","Epoch 100/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0663 - accuracy: 0.9722 - val_loss: 0.6770 - val_accuracy: 0.8156\n","Epoch 101/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0540 - accuracy: 0.9792 - val_loss: 0.5890 - val_accuracy: 0.8245\n","Epoch 102/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.7203 - val_accuracy: 0.8298\n","Epoch 103/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0391 - accuracy: 0.9863 - val_loss: 0.6055 - val_accuracy: 0.8209\n","Epoch 104/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0474 - accuracy: 0.9878 - val_loss: 0.5977 - val_accuracy: 0.8156\n","Epoch 105/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0558 - accuracy: 0.9791 - val_loss: 0.5859 - val_accuracy: 0.8174\n","Epoch 106/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.6864 - val_accuracy: 0.8227\n","Epoch 107/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0513 - accuracy: 0.9806 - val_loss: 0.8123 - val_accuracy: 0.7979\n","Epoch 108/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.6476 - val_accuracy: 0.8138\n","Epoch 109/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9883 - val_loss: 0.6777 - val_accuracy: 0.8209\n","Epoch 110/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0545 - accuracy: 0.9838 - val_loss: 0.6756 - val_accuracy: 0.8191\n","Epoch 111/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.5718 - val_accuracy: 0.8227\n","Epoch 112/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0272 - accuracy: 0.9899 - val_loss: 0.7072 - val_accuracy: 0.8174\n","Epoch 113/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.8277 - val_accuracy: 0.8032\n","Epoch 114/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 0.6820 - val_accuracy: 0.8387\n","Epoch 115/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.7790 - val_accuracy: 0.8333\n","Epoch 116/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.7312 - val_accuracy: 0.8333\n","Epoch 117/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0261 - accuracy: 0.9929 - val_loss: 0.7674 - val_accuracy: 0.8209\n","Epoch 118/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9916 - val_loss: 0.7933 - val_accuracy: 0.8440\n","Epoch 119/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.8923 - val_accuracy: 0.8191\n","Epoch 120/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.7239 - val_accuracy: 0.8121\n","Epoch 121/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0292 - accuracy: 0.9886 - val_loss: 0.7295 - val_accuracy: 0.8227\n","Epoch 122/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.6995 - val_accuracy: 0.8121\n","Epoch 123/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.8364 - val_accuracy: 0.8138\n","Epoch 124/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.6836 - val_accuracy: 0.8209\n","Epoch 125/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.8092 - val_accuracy: 0.8050\n","Epoch 126/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.7135 - val_accuracy: 0.8280\n","Epoch 127/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.7593 - val_accuracy: 0.8209\n","Epoch 128/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.7493 - val_accuracy: 0.8280\n","Epoch 129/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.8172 - val_accuracy: 0.8209\n","Epoch 130/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.7439 - val_accuracy: 0.8422\n","Epoch 131/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9889 - val_loss: 0.8374 - val_accuracy: 0.8333\n","Epoch 132/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.8245 - val_accuracy: 0.8333\n","Epoch 133/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.9619 - val_accuracy: 0.8174\n","Epoch 134/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.6806 - val_accuracy: 0.8333\n","Epoch 135/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.8022 - val_accuracy: 0.8227\n","Epoch 136/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.8629 - val_accuracy: 0.8262\n","Epoch 137/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.7184 - val_accuracy: 0.8298\n","Epoch 138/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.8120 - val_accuracy: 0.8316\n","Epoch 139/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.8084 - val_accuracy: 0.8298\n","Epoch 140/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.7614 - val_accuracy: 0.8316\n","Epoch 141/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.8424 - val_accuracy: 0.8262\n","Epoch 142/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.9376 - val_accuracy: 0.8280\n","Epoch 143/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.8332 - val_accuracy: 0.8121\n","Epoch 144/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.8577 - val_accuracy: 0.8121\n","Epoch 145/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.8191\n","Epoch 146/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0236 - accuracy: 0.9896 - val_loss: 0.8052 - val_accuracy: 0.8174\n","Epoch 147/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 1.0098 - val_accuracy: 0.8245\n","Epoch 148/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.9282 - val_accuracy: 0.8280\n","Epoch 149/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.9175 - val_accuracy: 0.8262\n","Epoch 150/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.9083 - val_accuracy: 0.8156\n","Epoch 151/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.9652 - val_accuracy: 0.7837\n","Epoch 152/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.8909 - val_accuracy: 0.8316\n","Epoch 153/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.7960 - val_accuracy: 0.8280\n","Epoch 154/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.9166 - val_accuracy: 0.8191\n","Epoch 155/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.9569 - val_accuracy: 0.8209\n","Epoch 156/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.9321 - val_accuracy: 0.8316\n","Epoch 157/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.8856 - val_accuracy: 0.8298\n","Epoch 158/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.9032 - val_accuracy: 0.8245\n","Epoch 159/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 1.0217 - val_accuracy: 0.8121\n","Epoch 160/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.9056 - val_accuracy: 0.8351\n","Epoch 161/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 1.0822 - val_accuracy: 0.8067\n","Epoch 162/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 1.0276 - val_accuracy: 0.8227\n","Epoch 163/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.9542 - val_accuracy: 0.8121\n","Epoch 164/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 1.0492 - val_accuracy: 0.8032\n","Epoch 165/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 1.1110 - val_accuracy: 0.7979\n","Epoch 166/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.9950 - val_loss: 1.0432 - val_accuracy: 0.8103\n","Epoch 167/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.8068 - val_accuracy: 0.8209\n","Epoch 168/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.9050 - val_accuracy: 0.8191\n","Epoch 169/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.8606 - val_accuracy: 0.8174\n","Epoch 170/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.9574 - val_accuracy: 0.8156\n","Epoch 171/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.8315 - val_accuracy: 0.8440\n","Epoch 172/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 1.0234 - val_accuracy: 0.8138\n","Epoch 173/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 1.0035 - val_accuracy: 0.8067\n","Epoch 174/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.8978 - val_accuracy: 0.8262\n","Epoch 175/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 1.0182 - val_accuracy: 0.8156\n","Epoch 176/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0210 - accuracy: 0.9959 - val_loss: 0.9028 - val_accuracy: 0.8387\n","Epoch 177/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.8262\n","Epoch 178/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.9862 - val_accuracy: 0.8245\n","Epoch 179/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 0.7916 - val_accuracy: 0.8351\n","Epoch 180/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 1.1189 - val_accuracy: 0.8298\n","Epoch 181/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.9398 - val_accuracy: 0.8156\n","Epoch 182/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.9857 - val_accuracy: 0.8174\n","Epoch 183/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.8156\n","Epoch 184/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0525 - val_accuracy: 0.8174\n","Epoch 185/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1414 - val_accuracy: 0.8245\n","Epoch 186/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 1.0629 - val_accuracy: 0.8121\n","Epoch 187/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 1.0337 - val_accuracy: 0.8209\n","Epoch 188/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0501 - val_accuracy: 0.8227\n","Epoch 189/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.9822 - val_accuracy: 0.8191\n","Epoch 190/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.9677 - val_accuracy: 0.8298\n","Epoch 191/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0716 - val_accuracy: 0.8227\n","Epoch 192/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 1.0538 - val_accuracy: 0.8298\n","Epoch 193/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.1870 - val_accuracy: 0.8227\n","Epoch 194/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.1216 - val_accuracy: 0.8050\n","Epoch 195/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.9261 - val_accuracy: 0.8280\n","Epoch 196/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 1.0263 - val_accuracy: 0.8138\n","Epoch 197/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.8646 - val_accuracy: 0.8404\n","Epoch 198/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.8298\n","Epoch 199/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.9674 - val_accuracy: 0.8280\n","Epoch 200/200\n","137/137 [==============================] - 1s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0869 - val_accuracy: 0.8138\n"]}]},{"cell_type":"markdown","metadata":{"id":"YhAwhSjwEpBZ"},"source":["## DataAugmentation 적용해보기 \n","## ImageDataGenerator사용하거나, 직접 만들어보기"],"id":"YhAwhSjwEpBZ"},{"cell_type":"code","metadata":{"id":"W_ul3JXMEpxJ"},"source":[""],"id":"W_ul3JXMEpxJ","execution_count":null,"outputs":[]}]}